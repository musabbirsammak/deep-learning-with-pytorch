{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This patch is to display epoch results while using Visual Studio Code\n",
    "from IPython.display import clear_output, DisplayHandle\n",
    "def update_patch(self, obj):\n",
    "    clear_output(wait=True)\n",
    "    self.display(obj)\n",
    "DisplayHandle.update = update_patch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model\n",
    "To define a custom model using PyTorch, you need to create a class that inherits from the `nn.Module` class provided by the PyTorch library. The `nn.Module`, which allows layers to be stacked to form a network, is the most commonly used approach for building a Neural Network in PyTorch.\n",
    "\n",
    "## nn.Liner\n",
    "The Linear layer, also known as a fully connected layer or dense layer, is best represented by $f(wx + b)$, where $x$ represents a tensor containing the input features, $w$ and $b$ are the weight matrix and bias vector, respectively, and $f$ is the activation function. Because each layer in a NN receives input from the previous layer, its dimensionality is fixed. Typically, we only need to consider output dimensionality when designing a NN architecture. We can initialize a Linear layer using the following syntax.\n",
    "\n",
    "`linear_layer = nn.Linear(in_features, out_features, bias=True)`\n",
    "\n",
    "- `in_features` specifies the number of input features or dimensions.\n",
    "- `out_features` specifies the number of output features or dimensions.\n",
    "- `bias indicates` whether to include a bias term in the linear transformation (default is True).\n",
    "\n",
    "When the forward pass is called on the `nn.Linear` layer, it performs the following computations:\n",
    "- `Matrix multiplication:` The input tensor is multiplied with a weight matrix of shape (`out_features`, `in_features`). The weight matrix determines the learned parameters of the linear transformation and is internally stored in the `nn.Linear` module.\n",
    "- `Addition of bias:` If `bias=True`, a bias term of shape (`out_features`,) is added element-wise to the result of the matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Initializing a Linear layer that will take 784 input features and output 10 features\n",
    "linear = torch.nn.Linear(in_features=784, out_features=10, bias=True)\n",
    "# The layer has 784 weights for each output neurons, hence 10x784\n",
    "print(linear.weight.shape)\n",
    "# The layer has 10 bias for 10 output neurons\n",
    "print(linear.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# Generates some random data of size 64x784 (batch size x features)\n",
    "data = torch.randn((64, 784))\n",
    "# Forward pass, multiplying 784 weights with 784 features\n",
    "outputs = linear(data)\n",
    "# Shape of the output will be 10 output features for each of the 64 data\n",
    "print(outputs.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization\n",
    "\n",
    "In PyTorch, weight initialization methods determine the initial values assigned to the weights of neural network layers. Proper weight initialization is crucial for effective training and convergence of neural networks. PyTorch provides several common weight initialization methods, each with its own characteristics. Here are explanations of some commonly used weight initialization methods in PyTorch:\n",
    "\n",
    "- Uniform Initialization (`nn.init.uniform_`): This method initializes the weights with values drawn from a uniform distribution. It takes two arguments: `a` and `b`, representing the lower and upper bounds of the uniform distribution, respectively.\n",
    "- Normal Initialization (`nn.init.normal_`): This method initializes the weights with values drawn from a normal distribution (Gaussian distribution). It takes two arguments: `mean` and `std`, representing the mean and standard deviation of the normal distribution, respectively.\n",
    "- Xavier Initialization (`nn.init.xavier_uniform_` and `nn.init.xavier_normal_`): Xavier initialization, also known as `Glorot initialization`, is designed to work well with activation functions that have linear characteristics, such as `sigmoid` or `tanh`. `nn.init.xavier_uniform_` initializes the weights uniformly by drawing values from a uniform distribution with bounds determined by the `fan-in` and `fan-out` of the layer. `nn.init.xavier_normal_` initializes the weights from a normal distribution with zero mean and a variance determined by the `fan-in` and `fan-out` of the layer.\n",
    "- He Initialization (`nn.init.kaiming_uniform_` and `nn.init.kaiming_normal_`): He initialization is designed for activation functions with `rectified linear unit (ReLU)` or its variants. `nn.init.kaiming_uniform_` initializes the weights uniformly using a uniform distribution determined by the `fan-in` of the layer. `nn.init.kaiming_normal_` initializes the weights from a normal distribution with zero mean and a variance determined by the `fan-in` of the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[14.1827, 19.1087, 17.5157,  ..., 18.4032, 18.0875, 11.0537],\n",
       "        [13.2255, 18.5650, 17.6809,  ..., 11.5792, 12.9408, 13.9958],\n",
       "        [16.2591, 17.9096, 10.2327,  ..., 19.9633, 12.9072, 16.8092],\n",
       "        ...,\n",
       "        [19.1229, 18.3452, 18.2393,  ..., 18.0992, 11.4814, 14.1419],\n",
       "        [10.8830, 14.6537, 15.9298,  ..., 10.1425, 17.9116, 17.8116],\n",
       "        [10.4411, 12.4530, 10.4453,  ..., 12.6293, 12.7216, 19.6306]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liner = nn.Linear(in_features=10, out_features=1, bias=True)\n",
    "nn.init.uniform_(linear.weight, a=10, b=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[5.1325, 4.3566, 5.0857,  ..., 6.6201, 1.9182, 2.5746],\n",
       "        [6.5280, 7.9659, 4.0461,  ..., 3.9955, 5.2617, 4.6356],\n",
       "        [5.8426, 3.2491, 5.4528,  ..., 7.0663, 7.4926, 7.4323],\n",
       "        ...,\n",
       "        [3.2003, 4.2170, 4.5990,  ..., 0.4067, 5.3184, 5.6994],\n",
       "        [6.3685, 2.3249, 4.4892,  ..., 7.2444, 4.5465, 6.3840],\n",
       "        [6.1262, 1.3187, 6.2343,  ..., 3.5328, 3.6782, 2.5086]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liner = nn.Linear(in_features=10, out_features=1, bias=True)\n",
    "nn.init.normal_(linear.weight, mean=5, std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0267, -0.0071,  0.0242,  ...,  0.0293,  0.0399,  0.0873],\n",
       "        [ 0.0302,  0.0453,  0.0273,  ...,  0.0377, -0.0090,  0.0221],\n",
       "        [ 0.0429,  0.0717,  0.0486,  ..., -0.0208, -0.0237,  0.0387],\n",
       "        ...,\n",
       "        [ 0.0317, -0.0351,  0.0853,  ...,  0.1106, -0.0072,  0.0623],\n",
       "        [ 0.0445,  0.0290,  0.0084,  ..., -0.0848, -0.0619, -0.0020],\n",
       "        [ 0.0518,  0.0298, -0.1020,  ...,  0.0755, -0.0836,  0.0803]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liner = nn.Linear(in_features=10, out_features=1, bias=True)\n",
    "nn.init.kaiming_normal_(linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0646, -0.0578,  0.0169,  ..., -0.0700, -0.0438,  0.0082],\n",
       "        [ 0.0549,  0.0047, -0.0811,  ...,  0.0694, -0.0202,  0.0320],\n",
       "        [ 0.0073, -0.0778, -0.0712,  ...,  0.0288, -0.0054,  0.0132],\n",
       "        ...,\n",
       "        [-0.0806,  0.0283,  0.0164,  ..., -0.0418,  0.0827, -0.0269],\n",
       "        [-0.0093, -0.0573,  0.0183,  ...,  0.0729, -0.0847,  0.0775],\n",
       "        [ 0.0566,  0.0737, -0.0402,  ..., -0.0369, -0.0506, -0.0850]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liner = nn.Linear(in_features=10, out_features=1, bias=True)\n",
    "nn.init.xavier_uniform_(linear.weight)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "PyTorch provides various activation functions that introduce non-linearity in neural networks. Here are explanations of some commonly used activation functions in PyTorch, along with code examples and their advantages and disadvantages.\n",
    "\n",
    "- **ReLU (Rectified Linear Unit)** (`torch.relu`):\n",
    "  - Computational efficiency: ReLU is computationally efficient to compute compared to some other activation functions.\n",
    "  - Simplicity: ReLU is simple and easy to implement.\n",
    "  - Dead neurons: ReLU can lead to dead neurons, where neurons become non-responsive and do not contribute to learning.\n",
    "  - Output saturation: ReLU can suffer from output saturation, where a large number of neurons become inactive during training.\n",
    "- **Sigmoid** (`torch.sigmoid`):\n",
    "  - Output range: Sigmoid function squashes the output between 0 and 1, which can be useful for binary classification tasks.\n",
    "  - Smooth gradient: Sigmoid has a smooth derivative, making it well-suited for gradient-based optimization algorithms.\n",
    "  - Vanishing gradient: Sigmoid is prone to the vanishing gradient problem, where gradients become very small during backpropagation, leading to slower learning.\n",
    "  - Output saturation: Sigmoid can suffer from output saturation, where the output values tend to get close to the extremes (0 or 1), resulting in limited learning.\n",
    "- **Tanh** (`torch.tanh`):\n",
    "  - Output range: Tanh function squashes the output between -1 and 1, which can be useful for capturing negative values.\n",
    "  - Zero-centered: Tanh is zero-centered, which can help in convergence during optimization.\n",
    "  - Vanishing gradient: Tanh is also prone to the vanishing gradient problem.\n",
    "  - Output saturation: Tanh can suffer from output saturation similar to the sigmoid function.\n",
    "- **LeakyReLU** (`torch.nn.LeakyReLU`):\n",
    "  - Avoids dead neurons: LeakyReLU helps to avoid the problem of dead neurons by allowing small negative values.\n",
    "  - Linear region: LeakyReLU has a linear region for negative inputs, which can provide learning even when the gradient is negative.\n",
    "  - Hyperparameter choice: The choice of the negative slope parameter requires tuning.\n",
    "- **ELU** (`torch.nn.ELU`):\n",
    "  - ELU has negative values for x <= 0, allowing the activation to capture negative information.\n",
    "  - ELU helps mitigate the vanishing gradient problem by providing non-zero gradients for negative inputs, which can aid in better optimization.\n",
    "  - ELU can provide better learning representations compared to traditional activation functions.\n",
    "  - ELU introduces a slight computational overhead compared to other activation functions due to the exponential operation.\n",
    "  - ELU may be sensitive to the choice of the hyperparameter alpha, which needs to be carefully tuned.\n",
    "- **SELU (Scaled Exponential Linear Unit)** (`nn.SELU`):\n",
    "  - SELU is a self-normalizing activation function, designed to ensure that the mean and standard deviation of the activations remain stable as the network deepens.\n",
    "  - SELU has self-normalizing properties, allowing the mean and standard deviation of activations to remain stable as the network deepens. This can aid in training deep neural networks.\n",
    "  - SELU can reduce the need for other regularization techniques, such as dropout or batch normalization.\n",
    "  - SELU can provide improved performance compared to other activation functions in certain scenarios.\n",
    "  - SELU requires careful initialization and scaling of weights to ensure the self-normalizing properties.\n",
    "  - SELU is not recommended for networks with non-sequential architectures or networks that utilize other normalization techniques.\n",
    "- **Softmax** (`torch.softmax`):\n",
    "  - Probability distribution: Softmax transforms the input values into a probability distribution, which is useful for multi-class classification tasks.\n",
    "  - Interpretability: Softmax outputs can be interpreted as class probabilities.\n",
    "  - Sensitivity to outliers: Softmax is sensitive to outliers and can produce large outputs for extreme input values.\n",
    "  - Lack of sparsity: Softmax tends to produce dense output vectors with non-zero probabilities for most classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7961e-01,  3.3568e-01, -8.6302e-04,  1.8407e-03, -4.3542e-03,\n",
       "          2.1144e-01,  1.8037e-01,  4.3073e-01,  4.2648e-01, -1.3548e-02],\n",
       "        [ 1.7430e-01, -2.7524e-04, -1.0590e-02,  8.0253e-01,  1.2953e-01,\n",
       "          5.6662e-01, -1.4731e-04, -9.5626e-03,  2.3697e-01,  9.9528e-01],\n",
       "        [ 5.7706e-02,  6.1784e-01,  4.6256e-01, -4.7602e-03, -1.1160e-03,\n",
       "         -7.2501e-03, -7.3342e-03,  8.5763e-02,  3.9352e-01,  9.5922e-01],\n",
       "        [-4.4337e-03, -5.5241e-03, -1.1487e-02,  2.2593e-01,  3.0301e-03,\n",
       "          2.5830e-03, -2.7371e-04,  8.7060e-01,  5.5905e-01,  3.4141e-01],\n",
       "        [ 4.4911e-01, -1.1538e-03, -7.9182e-04, -3.8672e-03, -9.7753e-04,\n",
       "          3.4488e-01, -1.4066e-03,  1.4861e+00,  1.6382e-01,  4.7978e-01],\n",
       "        [-2.0241e-03, -3.3248e-03, -4.5813e-03, -3.4967e-03,  6.3147e-01,\n",
       "         -2.6534e-03, -5.7521e-03, -4.2019e-03, -2.7875e-03, -2.7169e-03],\n",
       "        [-4.5183e-04, -5.6864e-03,  1.7076e-01, -4.2472e-03, -6.1661e-03,\n",
       "         -8.0808e-03,  3.0534e-01, -2.3562e-03,  3.5638e-01,  1.5334e-01],\n",
       "        [-8.8490e-03,  5.1478e-01, -3.9047e-03, -4.8263e-03, -9.0631e-03,\n",
       "          1.3123e-01,  6.5779e-01, -3.1020e-03,  1.0894e+00, -1.1149e-03],\n",
       "        [-6.2793e-03,  6.1522e-01, -3.6139e-03, -5.2095e-03, -3.4800e-03,\n",
       "          6.0202e-01, -4.3420e-03,  5.8669e-01,  9.0217e-02, -2.8634e-03],\n",
       "        [ 2.3751e-01, -4.0809e-03, -1.6532e-03,  5.8634e-01, -5.5654e-03,\n",
       "         -2.0652e-02, -3.7570e-03,  9.4452e-01, -6.0514e-03, -8.3423e-03],\n",
       "        [-7.0339e-03, -3.3892e-03,  2.7501e-01,  2.2375e-01, -2.7840e-03,\n",
       "          2.5752e-01, -2.9181e-03, -4.1632e-03, -1.0148e-03,  5.2152e-01],\n",
       "        [-8.7132e-03,  5.5221e-01,  1.3461e-01, -1.1824e-03,  6.8019e-01,\n",
       "         -1.2068e-03,  2.0342e-01, -2.3017e-03,  1.1015e-01, -1.6352e-03],\n",
       "        [-7.9811e-04,  4.5045e-02,  9.2359e-02,  7.3360e-01,  3.5518e-01,\n",
       "          5.0438e-01, -1.2454e-02, -2.1521e-03, -2.2049e-04,  4.6029e-01],\n",
       "        [-4.6658e-03,  2.4928e-01,  1.0655e+00, -3.8590e-04,  1.3835e+00,\n",
       "          2.8897e-01, -2.9526e-04, -4.4565e-03, -3.7514e-03,  2.9699e-02],\n",
       "        [-7.5104e-03, -7.1480e-03,  3.3970e-01,  4.9460e-01, -6.2124e-04,\n",
       "          2.7628e-01, -6.3633e-03, -9.4198e-03,  1.6030e-01,  2.1719e-01],\n",
       "        [-5.4202e-03, -1.3832e-03,  2.1306e-01,  8.0924e-01,  6.1358e-01,\n",
       "          5.2136e-01, -3.7258e-03, -3.0934e-03, -6.9587e-03,  1.1454e-01],\n",
       "        [ 1.3627e-01,  7.5479e-02, -7.2780e-03, -5.4421e-04,  2.2332e-01,\n",
       "         -7.3420e-04,  1.0393e+00,  6.7755e-01,  5.7757e-01, -9.3654e-03],\n",
       "        [ 3.7607e-01,  1.8673e-01,  6.9122e-02,  4.4638e-01,  2.4354e-02,\n",
       "          2.8089e-02, -3.3198e-03,  3.6950e-01,  3.3956e-01,  3.0963e-01],\n",
       "        [-4.6461e-03,  8.4933e-01, -8.6963e-05,  1.5213e+00, -3.9665e-03,\n",
       "          3.4417e-01,  9.9601e-02,  1.3545e-01,  1.1372e+00, -9.5851e-03],\n",
       "        [-5.6030e-04,  6.1300e-01, -3.6155e-03,  1.2557e+00,  4.8255e-01,\n",
       "         -6.0007e-03,  1.4457e-01, -5.5525e-03,  8.4757e-02,  2.7983e-02],\n",
       "        [-3.2898e-03,  6.9398e-01, -2.3932e-03, -7.5461e-03, -1.4056e-03,\n",
       "          3.5543e-01,  1.1644e-01, -7.2975e-03, -4.3663e-04, -3.0343e-03],\n",
       "        [ 9.5796e-01, -5.2959e-03, -6.4370e-03,  1.6326e-02,  1.3629e+00,\n",
       "         -1.9504e-03,  3.8581e-01,  1.4865e-01, -1.8692e-03,  2.2125e-01],\n",
       "        [-1.0880e-02, -3.5482e-03,  6.0739e-02,  6.3550e-02, -4.2481e-04,\n",
       "          1.8119e-01,  1.3761e-01, -2.4821e-03, -1.4109e-03,  5.5076e-01],\n",
       "        [-8.2882e-03, -8.3710e-03,  4.3615e-02,  1.7761e-02, -6.9493e-03,\n",
       "         -3.5270e-03,  6.4070e-02, -5.7418e-03,  8.5988e-02, -5.1595e-03],\n",
       "        [-1.9550e-03, -2.6941e-03,  3.6700e-01,  8.7675e-01,  3.1907e-02,\n",
       "         -1.0400e-02, -3.6749e-03, -5.7021e-03,  6.4515e-01,  2.4606e-01],\n",
       "        [ 3.9401e-01,  2.8617e-01, -3.7784e-03,  6.3126e-01, -5.1805e-03,\n",
       "         -6.2239e-04, -3.3583e-03, -5.8637e-03,  2.5894e-01,  1.7597e-01],\n",
       "        [ 4.3046e-01,  8.5409e-01,  1.3910e-01, -3.1525e-03, -2.0075e-03,\n",
       "          1.2135e-02,  5.1523e-01,  2.5082e-02,  1.2774e-01,  1.2102e-01],\n",
       "        [-1.3525e-03,  3.6835e-01, -1.0445e-03, -1.8759e-03, -6.6659e-05,\n",
       "          3.0740e-01,  9.2681e-01, -1.0468e-02, -8.4064e-03, -1.6985e-04],\n",
       "        [-1.0846e-02, -7.4076e-03,  5.5128e-01,  5.1538e-01, -1.7834e-03,\n",
       "          8.4392e-01, -4.9087e-04, -6.4893e-04,  3.2722e-02,  2.1671e-02],\n",
       "        [ 4.0549e-02,  8.2707e-03,  5.9763e-01, -5.4945e-03, -3.8119e-03,\n",
       "         -9.0123e-03, -1.1866e-02, -3.9397e-03, -7.6771e-03, -2.8061e-03],\n",
       "        [-3.9791e-03, -6.4158e-03, -5.3363e-03, -4.6164e-03, -1.2546e-05,\n",
       "          5.9174e-01,  5.6006e-01,  4.6153e-01,  2.2638e-01,  5.7332e-02],\n",
       "        [ 3.5327e-01, -2.1226e-03,  8.3717e-02, -8.0128e-03,  5.6398e-02,\n",
       "         -1.3385e-03,  5.6418e-01, -6.1369e-03, -3.2604e-03, -4.2781e-03],\n",
       "        [ 4.6189e-01, -1.1733e-03, -1.1038e-03, -1.9323e-03, -1.4486e-02,\n",
       "         -8.2400e-03, -6.0097e-03, -4.0948e-03,  6.6939e-01,  1.1807e+00],\n",
       "        [-8.4931e-06,  1.2677e+00, -1.8345e-03, -2.4587e-03, -5.8797e-05,\n",
       "         -2.3460e-03, -1.7880e-03,  7.6593e-01, -3.3423e-03,  1.4745e+00],\n",
       "        [-7.0543e-03, -9.9582e-04,  1.6213e-01, -1.1943e-03,  5.4386e-01,\n",
       "          3.9148e-01,  1.3191e+00, -9.4600e-04,  3.4886e-01, -8.0305e-03],\n",
       "        [ 2.3111e-01, -9.3504e-04,  1.4306e-01,  1.9516e-01,  8.8576e-01,\n",
       "         -8.1334e-03, -1.3513e-02, -2.5251e-03, -9.6014e-03, -1.1475e-02],\n",
       "        [ 2.2878e-01,  4.4322e-01,  2.0047e-01, -7.7133e-03, -2.5206e-03,\n",
       "          1.7569e-01,  4.3582e-01,  6.4777e-02,  1.7717e-02, -1.0905e-02],\n",
       "        [-6.6135e-03,  6.1194e-01,  3.3234e-01, -9.5507e-04, -5.4662e-03,\n",
       "         -4.3364e-03,  5.3169e-01,  1.8088e-02, -7.6791e-04,  1.4875e-01],\n",
       "        [-1.2272e-02, -6.7120e-03, -6.6074e-03,  4.7431e-02,  5.6553e-01,\n",
       "          3.2533e-01, -1.2953e-03,  4.7844e-01,  6.0745e-01, -6.0945e-03],\n",
       "        [ 1.1086e+00,  5.7253e-01,  4.3602e-01,  2.4439e-01, -3.8931e-03,\n",
       "          1.1901e-01, -6.2629e-03,  6.7285e-02, -1.8220e-03, -6.6056e-03],\n",
       "        [-3.8430e-03,  7.8340e-01, -1.4120e-03,  4.4425e-01, -2.3570e-03,\n",
       "          6.0685e-01, -4.2238e-03,  1.0395e+00,  5.2955e-02, -5.5482e-03],\n",
       "        [-9.5415e-04,  1.1072e+00, -1.6650e-02,  3.1912e-01, -1.0692e-02,\n",
       "         -6.9098e-04, -5.9096e-03, -7.9279e-03,  6.1041e-01, -5.5588e-04],\n",
       "        [-7.2730e-04, -2.2412e-03,  1.3390e+00, -5.7505e-03,  1.2371e-01,\n",
       "         -4.6818e-03,  1.7932e-01,  3.6063e-01,  8.2761e-02,  1.9322e-01],\n",
       "        [ 7.7729e-01, -1.2124e-03,  2.0666e-01, -1.9447e-03, -7.1231e-03,\n",
       "          3.6948e-01, -3.2034e-03, -3.4749e-03,  5.3495e-01,  1.2518e-01],\n",
       "        [-1.1324e-05,  4.0888e-01,  1.2043e-01, -6.5745e-04, -4.5522e-03,\n",
       "         -5.4195e-03,  1.9362e-01, -4.1794e-04, -3.8385e-03,  4.9835e-01],\n",
       "        [ 4.2068e-01,  6.4570e-02,  8.2088e-01,  2.3516e-01,  7.8436e-01,\n",
       "          4.4040e-01, -1.2901e-03, -7.1144e-03,  4.6676e-01,  6.8996e-01],\n",
       "        [-3.3273e-03, -8.8070e-03, -1.3535e-02,  4.2531e-01, -9.2553e-03,\n",
       "         -5.3822e-03,  8.2397e-01,  5.8986e-01,  2.0475e+00, -8.6408e-03],\n",
       "        [-2.2445e-03,  2.1100e-01, -1.5148e-03,  8.3474e-01, -4.0394e-04,\n",
       "         -1.2350e-02, -3.5548e-03, -4.6166e-03,  9.8950e-01,  3.2973e-01],\n",
       "        [-4.8846e-03,  3.2574e-01,  8.3304e-01, -1.6775e-04, -1.1651e-02,\n",
       "         -7.5954e-03, -2.6343e-03, -7.9198e-03,  9.7757e-01,  1.1888e-01],\n",
       "        [ 5.4787e-02, -2.7312e-03,  4.8580e-01,  1.0406e-01, -2.4835e-03,\n",
       "         -3.1488e-03,  5.6087e-02,  5.0555e-02, -3.6505e-04,  4.5064e-01],\n",
       "        [ 3.8748e-01, -1.0866e-02,  3.8647e-01, -3.9548e-03, -4.2275e-03,\n",
       "          1.8375e-01, -4.9980e-03,  4.2628e-01, -2.3589e-03,  1.2550e+00],\n",
       "        [ 6.6279e-01, -3.9314e-03, -2.1483e-03,  1.6051e-01, -5.3015e-03,\n",
       "          4.0060e-01, -9.3071e-04, -5.6261e-04, -2.4581e-03, -7.1487e-03],\n",
       "        [-1.8990e-03,  1.0517e-01,  4.9881e-01, -5.3187e-03, -2.9856e-03,\n",
       "          7.1477e-01,  1.7623e-01, -2.0113e-03, -4.5033e-03, -7.6975e-03],\n",
       "        [ 6.3601e-01,  1.3965e-01,  2.6204e-01,  1.1698e-01, -4.0855e-03,\n",
       "         -6.5983e-03,  9.7690e-01,  1.1470e+00,  2.4766e-02,  9.7858e-01],\n",
       "        [ 4.7993e-01, -6.3476e-03, -2.3624e-03, -5.1731e-03, -5.8422e-03,\n",
       "          7.3801e-01,  9.7094e-02, -1.0508e-02,  3.3590e-01, -3.6002e-03],\n",
       "        [ 6.3644e-01,  2.5276e-01, -3.8274e-03, -2.7731e-03,  7.9773e-01,\n",
       "          1.2682e+00, -1.4631e-03, -5.3357e-03,  7.6888e-01,  4.7578e-01],\n",
       "        [-3.7668e-03,  2.1039e-01, -7.1473e-03, -3.4817e-03, -2.7384e-03,\n",
       "         -6.0326e-03,  4.2727e-01, -8.7055e-03,  4.3770e-01, -1.3104e-03],\n",
       "        [ 6.9533e-01, -1.0058e-03,  5.8963e-01, -7.5160e-03,  9.9812e-01,\n",
       "         -3.7783e-03,  3.5015e-01, -2.9698e-04, -2.8110e-03,  1.9430e-01],\n",
       "        [ 5.7815e-01,  2.8711e-01, -4.4282e-03,  1.1397e-01, -3.2820e-04,\n",
       "         -9.9786e-03,  5.9424e-01,  2.2098e-01, -1.0872e-04,  1.5047e+00],\n",
       "        [-7.2792e-03, -1.6114e-02, -8.1581e-03, -6.4216e-03,  1.8882e-01,\n",
       "          1.2420e+00,  3.8174e-01, -1.7020e-03, -4.1603e-03,  1.3406e+00],\n",
       "        [-2.3393e-03, -4.1553e-03, -1.7462e-02,  7.9927e-01,  6.1561e-02,\n",
       "         -3.7184e-04, -5.6505e-03,  5.5057e-01, -1.0530e-02,  1.7457e+00],\n",
       "        [ 1.7645e-01, -6.0463e-03,  2.9050e-01,  1.4266e-01,  3.8993e-01,\n",
       "          1.9333e-01, -3.9581e-03,  5.4921e-01, -1.7735e-03,  3.1257e-01],\n",
       "        [-2.2891e-03,  5.2133e-01, -3.5203e-04,  6.9685e-01, -3.9409e-03,\n",
       "         -8.0167e-03,  6.5037e-01,  2.5541e-01, -4.4800e-03,  1.1819e-01],\n",
       "        [-2.7687e-04, -1.5374e-03, -1.1123e-04,  1.7926e-01,  8.8206e-01,\n",
       "         -9.5657e-03,  1.8122e-01,  3.5520e-01,  3.3401e-01,  2.9916e-01]],\n",
       "       grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leakyRelu = nn.LeakyReLU(negative_slope=0.01)\n",
    "leakyRelu(outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizations\n",
    "\n",
    "In PyTorch, you can implement regularization techniques to prevent overfitting and improve the generalization of your neural network models. Here are a few commonly used regularization techniques and their implementations in PyTorch:\n",
    "\n",
    "- **L2 Regularization (Weight Decay)**: L2 regularization, also known as weight decay, adds a penalty term to the loss function that encourages smaller weight values. PyTorch provides a built-in option to apply L2 regularization while defining the optimizer. You can specify the `weight_decay` parameter when creating an optimizer.\n",
    "- **L1 regularization**: It encourages sparsity in the weights by adding a penalty term that promotes small absolute values. PyTorch does not have built-in support for L1 regularization in optimizers, but you can manually add the L1 penalty term to the loss function and optimize it.\n",
    "- **Dropout**: Dropout randomly sets a fraction of the input units to zero during training, which helps to prevent overfitting and encourages the network to learn more robust features. PyTorch provides a `nn.Dropout` module that can be added to your model's architecture."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Custom Model\n",
    "In this case, we'd like to define a model with two hidden layers. The first takes $784$ features as input and projects them to $25$ neurons. Because we have $10$ class labels, the second layer receives the output of the previous layer (which has a size of $25$) and projects it to three $10$ output neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple classifier\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=0.20)\n",
    "        self.fc1 = nn.Linear(in_features, 25)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(25, 15)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        self.output = nn.Linear(15, num_classes)\n",
    "        nn.init.kaiming_normal_(self.output.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accelerate operations in the neural network, we move it to the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# sets device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# initializes and sends the model to appropriate GPU/CPU\n",
    "model = NN(784, 10).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader & Preprocessing\n",
    "PyTorch offers domain-specific libraries such as TorchText, TorchVision, and TorchAudio, all of which include datasets. All of these are subclasses of `torch.utils.data.Dataset` and, therefore, can be used in `torch.utils.data.DataLoader` class. Find more about torchvision datasets at [here](https://pytorch.org/vision/0.8/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# load data\n",
    "train_data = datasets.MNIST(\n",
    "    root='./res/datasets',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='./res/datasets',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# Checks dimensions of each minibatch\n",
    "x, y = next(iter(train_loader))\n",
    "print(x.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks how the target labels are encoded\n",
    "y[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters & Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets hyperparameters\n",
    "in_features = 784\n",
    "num_classes = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we need a loss function and an optimizer.\n",
    "\n",
    "## Loss Functions\n",
    "PyTorch provides a wide range of loss functions that cater to various machine learning tasks. Here's an explanation of some commonly used loss functions in PyTorch:\n",
    "\n",
    "- **Mean Squared Error (MSE) Loss**: The MSE loss calculates the average squared difference between the predicted and target values. It is commonly used for regression tasks.\n",
    "  - `loss_fn = nn.MSELoss()`\n",
    "- **Binary Cross Entropy Loss**: Binary cross entropy loss measures the dissimilarity between binary predictions and binary targets. It is commonly used for binary classification tasks. The input to `torch.nn.BCELoss` is expected to be a tensor of sigmoid outputs between 0 and 1. The target values should be in the range [0, 1] representing the ground truth probabilities.\n",
    "  - `loss_fn = nn.BCELoss()`\n",
    "- **Binary Cross Entropy Loss with Logits**: Binary cross-entropy with logits loss is used for binary classification problems but takes logits as inputs instead of sigmoid outputs. This loss combines a sigmoid activation and binary cross-entropy loss in a single efficient computation. The input to `torch.nn.BCEWithLogitsLoss` is expected to be logits (real-valued scores) without applying sigmoid activation.\n",
    "  - `loss = nn.BCEWithLogitsLoss()`\n",
    "- **Cross Entropy Loss**: Cross entropy loss is used for multi-class classification tasks. It computes the negative log likelihood of the predicted class probabilities. The input to `torch.nn.CrossEntropyLoss` is expected to be logits (real-valued scores) without applying softmax activation. The target values should be class indices (integer labels) representing the ground truth class.\n",
    "  - `loss_fn = nn.CrossEntropyLoss()`\n",
    "- **Huber Loss**: Huber loss combines the best attributes of mean absolute error (MAE) and mean squared error (MSE) loss. It is less sensitive to outliers than MSE and provides a smoother loss landscape near zero.\n",
    "  - `loss_fn = nn.SmoothL1Loss()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "In PyTorch, there are several optimization algorithms (optimizers) available for training neural networks. Each optimizer has its own characteristics and can be suitable for different scenarios. Here are explanations of different optimizers in PyTorch:\n",
    "\n",
    "- **Stochastic Gradient Descent (SGD)**: SGD is a widely used optimization algorithm that updates the model parameters based on the gradients of the loss function with respect to those parameters.\n",
    "- **RMSprop (Root Mean Square Propagation)**: RMSprop is an adaptive optimization algorithm that divides the learning rate by a running average of the root mean squared gradients. It helps to stabilize the learning process and adapt the learning rate to different parameters.\n",
    "- **Adagrad (Adaptive Gradient Algorithm)**: Adagrad is an adaptive optimization algorithm that adapts the learning rate for each parameter based on the historical sum of squared gradients. It gives larger updates for infrequent parameters and smaller updates for frequent parameters.\n",
    "- **Adam (Adaptive Moment Estimation)**: Adam is an adaptive optimization algorithm that combines ideas from both AdaGrad and RMSProp. It adapts the learning rate for each parameter based on estimates of the first and second moments of the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_epoch = [0] * num_epochs\n",
    "acc = [0] * num_epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0| Loss 0.9416069771726926 | Accuracy 0.6893333196640015\n",
      "Epoch 1| Loss 0.8866419506152471 | Accuracy 0.7128666639328003\n",
      "Epoch 2| Loss 0.8943693260550499 | Accuracy 0.7093166708946228\n",
      "Epoch 3| Loss 0.8825760385394097 | Accuracy 0.7140499949455261\n",
      "Epoch 4| Loss 0.8927643306493759 | Accuracy 0.7110999822616577\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Moves the data to the GPU/CPU\n",
    "        data = data.to(device)\n",
    "        # Converts the 2D image into a 1-D vector\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        # Moves the target labels to GPU/CPU\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Make predictions with the current parameters\n",
    "        scores = model(data)\n",
    "        # Calculates loss of the current minibatch\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Resets the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # Compute gradients of loss function with respect to parameters\n",
    "        loss.backward()\n",
    "        # Updates parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_per_epoch[epoch] += loss.item() * data.size(0)\n",
    "        correct = (torch.argmax(scores, dim=1) == targets).float()\n",
    "        acc[epoch] += correct.mean()\n",
    "\n",
    "    loss_per_epoch[epoch] /= len(train_loader.dataset)\n",
    "    acc[epoch] /= (len(train_loader.dataset) / batch_size)\n",
    "    print('Epoch {}| Loss {} | Accuracy {}'.format(epoch, loss_per_epoch[epoch], acc[epoch]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving & Loading Models\n",
    "Trained models can be saved to disk and reused in the future. When you call `save(model)`, **you are saving both the model architecture and all of the learned parameters**. As a standard practice, we can save models with the 'pt' or 'pth' file extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models directory already exists!\n"
     ]
    }
   ],
   "source": [
    "if 'models' not in os.listdir():\n",
    "    os.mkdir('models')\n",
    "    print('models directory created!')\n",
    "else:\n",
    "    print('models directory already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/ann.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=784, out_features=25, bias=True)\n",
       "  (fc2): Linear(in_features=25, out_features=15, bias=True)\n",
       "  (output): Linear(in_features=15, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('models/ann.pth')\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, if you wanted, you could also save just the parameters, not the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/ann_state.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(784, 10)\n",
    "model.load_state_dict(torch.load('models/ann_state.pth'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            correct += (predictions == y).sum()\n",
    "            total += predictions.size(0)\n",
    "        model.train()\n",
    "        print('Accuracy: ', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  tensor(0.8491, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast.AI\n",
    "The `MNIST SAMPLE` dataset from fastai is a smaller version of the actual `MNIST Digits` dataset, and it contains images of only $5$ and $7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musab\\.fastai\\data\\mnist_sample\\labels.csv\n",
      "C:\\Users\\musab\\.fastai\\data\\mnist_sample\\train\n",
      "C:\\Users\\musab\\.fastai\\data\\mnist_sample\\valid\n"
     ]
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "for dir in path.ls():\n",
    "    print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Path('C:/Users/musab/.fastai/data/mnist_sample/train/3'), Path('C:/Users/musab/.fastai/data/mnist_sample/train/7')]\n",
      "[Path('C:/Users/musab/.fastai/data/mnist_sample/valid/3'), Path('C:/Users/musab/.fastai/data/mnist_sample/valid/7')]\n"
     ]
    }
   ],
   "source": [
    "print((path/'train').ls())\n",
    "print((path/'valid').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:  torch.Size([12396, 784])\n",
      "Validation Dataset:  torch.Size([2038, 784])\n"
     ]
    }
   ],
   "source": [
    "train_x = torch.cat((\n",
    "    torch.stack([tensor(Image.open(f)).reshape(-1) for f in (path/'train'/'3').ls().sorted()]) / 255.0,\n",
    "    torch.stack([tensor(Image.open(f)).reshape(-1) for f in (path/'train'/'7').ls().sorted()]) / 255.0\n",
    "), dim=0)\n",
    "print('Training Dataset: ', train_x.shape)\n",
    "\n",
    "valid_x = torch.cat((\n",
    "    torch.stack([tensor(Image.open(f)).reshape(-1) for f in (path/'valid'/'3').ls().sorted()]) / 255.0,\n",
    "    torch.stack([tensor(Image.open(f)).reshape(-1) for f in (path/'valid'/'7').ls().sorted()]) / 255.0\n",
    "), dim=0)\n",
    "print('Validation Dataset: ', valid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:  torch.Size([12396])\n",
      "Validation Dataset:  torch.Size([2038])\n"
     ]
    }
   ],
   "source": [
    "train_y = tensor([3] * len((path/'train'/'3').ls()) + [7] * len((path/'train'/'7').ls()))\n",
    "print('Train Dataset: ', train_y.shape)\n",
    "valid_y = tensor([3] * len((path/'valid'/'3').ls()) + [7] * len((path/'valid'/'7').ls()))\n",
    "print('Validation Dataset: ', valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(L(zip(train_x, train_y)), batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(L(zip(valid_x, valid_y)), batch_size=32, shuffle=True)\n",
    "dls = DataLoaders(train_loader, valid_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner\n",
    "The Learner class in the fastai library provides a high-level interface for training models. It encapsulates the model, data, optimizer, loss function, metrics, and other essential components. Here are explanations of some important parameters of the Learner class in fastai:\n",
    "\n",
    "- data (DataLoaders): This parameter represents the data loaders used for training and validation. It is an instance of the DataLoaders class, which contains the training and validation data along with other related settings.\n",
    "- model (nn.Module): The model parameter refers to the neural network model to be trained. It should be an instance of a PyTorch `nn.Module` subclass.\n",
    "- loss_func (callable): This parameter represents the loss function used during training. It should be a callable that takes the model predictions and target labels as inputs and returns a scalar value representing the loss.\n",
    "- opt_func (callable): The opt_func parameter specifies the optimizer function used for parameter updates during training. It should be a callable that takes the model parameters as input and returns an optimizer object.\n",
    "- metrics (list): The metrics parameter allows you to specify a list of evaluation metrics to be computed during training and validation. Each metric should be a callable that takes the model predictions and target labels as inputs and returns a value representing the metric score.\n",
    "- cbs (list): This parameter stands for callbacks, which are objects or functions that can be used to customize the behavior of the training process. You can pass a list of callback objects or functions to the cbs parameter.\n",
    "- splitter (callable): The splitter parameter is used to define how to split the data into training and validation sets.\n",
    "It should be a callable that takes the data and returns two lists or tuples representing the training and validation subsets.\n",
    "- wd (float or None): The wd parameter represents weight decay, which is a regularization technique that applies a penalty to the weights. If wd is a float value, weight decay is applied during training.\n",
    "- callbacks (list): The callbacks parameter is similar to cbs but is used to specify a list of callback objects that provide additional functionality during training.\n",
    "- learn (Learner): This parameter refers to the parent Learner object that can be used for callback chaining or accessing other aspects of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.049417</td>\n",
       "      <td>0.985280</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.052985</td>\n",
       "      <td>0.039178</td>\n",
       "      <td>0.990677</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.032094</td>\n",
       "      <td>0.041715</td>\n",
       "      <td>0.989205</td>\n",
       "      <td>0.010795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>0.036163</td>\n",
       "      <td>0.988714</td>\n",
       "      <td>0.011286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030255</td>\n",
       "      <td>0.043244</td>\n",
       "      <td>0.990186</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner = Learner(dls,\n",
    "                  NN(784, 10).to(device),\n",
    "                  opt_func=Adam,\n",
    "                  loss_func=nn.functional.cross_entropy,\n",
    "                  metrics=[accuracy, error_rate, top_k_accuracy],\n",
    "                  wd=0.1)\n",
    "learner.fit(5, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
