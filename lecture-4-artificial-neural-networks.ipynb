{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This patch is to display epoch results while using Visual Studio Code\n",
    "from IPython.display import clear_output, DisplayHandle\n",
    "def update_patch(self, obj):\n",
    "    clear_output(wait=True)\n",
    "    self.display(obj)\n",
    "DisplayHandle.update = update_patch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model\n",
    "The `nn.Module`, which allows layers to be stacked to form a network, is the most commonly used approach for building a Neural Network in PyTorch. We now have more control over the forward pass.\n",
    "\n",
    "The Linear layer, also known as a fully connected layer or dense layer, is best represented by $f(wx + b)$, where $x$ represents a tensor containing the input features, $w$ and $b$ are the weight matrix and bias vector, respectively, and $f$ is the activation function. Because each layer in a NN receives input from the previous layer, its dimensionality is fixed. Typically, we only need to consider output dimensionality when designing a NN architecture.\n",
    "\n",
    "In this case, we'd like to define a model with two hidden layers. The first takes $784$ features as input and projects them to $25$ neurons. Because we have $10$ class labels, the second layer receives the output of the previous layer (which has a size of $25$) and projects it to three $10$ output neurons.\n",
    "\n",
    "initializing model parameters with random weights is necessary to break the symmetry during backpropagationâ€”otherwise, a multilayer NN would be no more useful than a single-layer NN like logistic regression. When creating a PyTorch tensor, we can also use a random initialization scheme. `nn.init.xavier_normal_` and `nn.init.xavier_uniform_` are such two initialization methods. You can find many other initialization techniques in the `nn.init` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple classifier\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 25)\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(25, num_classes)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accelerate operations in the neural network, we move it to the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# initializes and sends the model to appropriate GPU/CPU\n",
    "model = NN(784, 10).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader & Preprocessing\n",
    "PyTorch offers domain-specific libraries such as TorchText, TorchVision, and TorchAudio, all of which include datasets. All of these are subclasses of `torch.utils.data.Dataset` and, therefore, can be used in `torch.utils.data.DataLoader` class. Find more about torchvision datasets at [here](https://pytorch.org/vision/0.8/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# load data\n",
    "train_data = datasets.MNIST(\n",
    "    root='./res/datasets',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='./res/datasets',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Checks dimensions of each minibatch\n",
    "x, y = next(iter(train_loader))\n",
    "print(x.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks how the target labels are encoded\n",
    "y[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters & Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets hyperparameters\n",
    "in_features = 784\n",
    "num_classes = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we need a loss function and an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_epoch = [0] * num_epochs\n",
    "acc = [0] * num_epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0| Loss 0.28610282474756243 | Accuracy 0.9149500131607056\n",
      "Epoch 1| Loss 0.19095433277487756 | Accuracy 0.9427833557128906\n",
      "Epoch 2| Loss 0.1652491458406051 | Accuracy 0.9521166682243347\n",
      "Epoch 3| Loss 0.15396445863743624 | Accuracy 0.9553833603858948\n",
      "Epoch 4| Loss 0.13811732213596503 | Accuracy 0.9598667025566101\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Moves the data to the GPU/CPU\n",
    "        data = data.to(device)\n",
    "        # Converts the 2D image into a 1-D vector\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        # Moves the target labels to GPU/CPU\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Make predictions with the current parameters\n",
    "        scores = model(data)\n",
    "        # Calculates loss of the current minibatch\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Resets the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # Compute gradients of loss function with respect to parameters\n",
    "        loss.backward()\n",
    "        # Updates parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_per_epoch[epoch] += loss.item() * data.size(0)\n",
    "        correct = (torch.argmax(scores, dim=1) == targets).float()\n",
    "        acc[epoch] += correct.mean()\n",
    "\n",
    "    loss_per_epoch[epoch] /= len(train_loader.dataset)\n",
    "    acc[epoch] /= (len(train_loader.dataset) / batch_size)\n",
    "    print('Epoch {}| Loss {} | Accuracy {}'.format(epoch, loss_per_epoch[epoch], acc[epoch]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving & Loading Models\n",
    "Trained models can be saved to disk and reused in the future. When you call `save(model)`, **you are saving both the model architecture and all of the learned parameters**. As a standard practice, we can save models with the 'pt' or 'pth' file extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models directory already exists!\n"
     ]
    }
   ],
   "source": [
    "if 'models' not in os.listdir():\n",
    "    os.mkdir('models')\n",
    "    print('models directory created!')\n",
    "else:\n",
    "    print('models directory already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/ann.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (fc1): Linear(in_features=784, out_features=25, bias=True)\n",
       "  (fc2): Linear(in_features=25, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('models/ann.pth')\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, if you wanted, you could also save just the parameters, not the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/ann_state.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(784, 10)\n",
    "model.load_state_dict(torch.load('models/ann_state.pth'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            correct += (predictions == y).sum()\n",
    "            total += predictions.size(0)\n",
    "        model.train()\n",
    "        print('Accuracy: ', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  tensor(0.9522, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast.AI\n",
    "The `MNIST SAMPLE` dataset from fastai is a smaller version of the actual `MNIST Digits` dataset, and it contains images of only $5$ and $7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musab\\.fastai\\data\\mnist_sample\\labels.csv\n",
      "C:\\Users\\musab\\.fastai\\data\\mnist_sample\\train\n",
      "C:\\Users\\musab\\.fastai\\data\\mnist_sample\\valid\n"
     ]
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "for dir in path.ls():\n",
    "    print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Path('C:/Users/musab/.fastai/data/mnist_sample/train/3'), Path('C:/Users/musab/.fastai/data/mnist_sample/train/7')]\n",
      "[Path('C:/Users/musab/.fastai/data/mnist_sample/valid/3'), Path('C:/Users/musab/.fastai/data/mnist_sample/valid/7')]\n"
     ]
    }
   ],
   "source": [
    "print((path/'train').ls())\n",
    "print((path/'valid').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:  torch.Size([12396, 784])\n",
      "Validation Dataset:  torch.Size([2038, 784])\n"
     ]
    }
   ],
   "source": [
    "train_x = torch.cat((\n",
    "    torch.stack([tensor(Image.open(f)).reshape(-1) for f in (path/'train'/'3').ls().sorted()]) / 255.0,\n",
    "    torch.stack([tensor(Image.open(f)).reshape(-1) for f in (path/'train'/'7').ls().sorted()]) / 255.0\n",
    "), dim=0)\n",
    "print('Training Dataset: ', train_x.shape)\n",
    "\n",
    "valid_x = torch.cat((\n",
    "    torch.stack([tensor(Image.open(f)).reshape(-1) for f in (path/'valid'/'3').ls().sorted()]) / 255.0,\n",
    "    torch.stack([tensor(Image.open(f)).reshape(-1) for f in (path/'valid'/'7').ls().sorted()]) / 255.0\n",
    "), dim=0)\n",
    "print('Validation Dataset: ', valid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:  torch.Size([12396])\n",
      "Validation Dataset:  torch.Size([2038])\n"
     ]
    }
   ],
   "source": [
    "train_y = tensor([3] * len((path/'train'/'3').ls()) + [7] * len((path/'train'/'7').ls()))\n",
    "print('Train Dataset: ', train_y.shape)\n",
    "valid_y = tensor([3] * len((path/'valid'/'3').ls()) + [7] * len((path/'valid'/'7').ls()))\n",
    "print('Validation Dataset: ', valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(L(zip(train_x, train_y)), batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(L(zip(valid_x, valid_y)), batch_size=32, shuffle=True)\n",
    "dls = DataLoaders(train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.040441</td>\n",
       "      <td>0.037430</td>\n",
       "      <td>0.986752</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.028806</td>\n",
       "      <td>0.050326</td>\n",
       "      <td>0.985280</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>0.044813</td>\n",
       "      <td>0.989205</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.032387</td>\n",
       "      <td>0.991168</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.011788</td>\n",
       "      <td>0.038770</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner = Learner(dls, NN(784, 10).to(device), opt_func=Adam, loss_func=nn.functional.cross_entropy, metrics=accuracy)\n",
    "learner.fit(5, lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
