{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent from Scratch\n",
    "In this tutorial, we will be building gradient descent algorithm from the scratch\n",
    "using `tensors` that we learned in the previous topic. It will test your knowledge\n",
    "on `tensors` and its operations. First, we will import all\n",
    "the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset\n",
    "We will use the MNIST Sample dataset from the `Fastai` repository. This dataset contains\n",
    "a stripped down version of the actual MNIST hand written digits. It contains the digits\n",
    "$3$ and $7$ only. Our task will be build a `Logistic Regression` classifier to classify\n",
    "the digits. First, we will create dataloaders for both training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/Users/musabbirhasansammak/.fastai/data/mnist_sample')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads MNIST dataset from Fast.ai repository\n",
    "# This trimmed dataset contains only 3s and 7s\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Path('/Users/musabbirhasansammak/.fastai/data/mnist_sample/valid'), Path('/Users/musabbirhasansammak/.fastai/data/mnist_sample/labels.csv'), Path('/Users/musabbirhasansammak/.fastai/data/mnist_sample/train')]\n"
     ]
    }
   ],
   "source": [
    "print(path.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Path('/Users/musabbirhasansammak/.fastai/data/mnist_sample/train/7'), Path('/Users/musabbirhasansammak/.fastai/data/mnist_sample/train/3')]\n",
      "\n",
      "[Path('/Users/musabbirhasansammak/.fastai/data/mnist_sample/valid/7'), Path('/Users/musabbirhasansammak/.fastai/data/mnist_sample/valid/3')]\n"
     ]
    }
   ],
   "source": [
    "print((path / 'train').ls())\n",
    "print()\n",
    "print((path / 'valid').ls())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = (path/'train/3').ls().sorted()\n",
    "sevens = (path/'train/7').ls().sorted()\n",
    "\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "\n",
    "stacked_sevens = torch.stack(seven_tensors).float() / 255\n",
    "stacked_threes = torch.stack(three_tensors).float() / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28 * 28)\n",
    "train_y = tensor([1] * len(threes) + [0] * len(sevens)).unsqueeze(1)\n",
    "\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAJM0lEQVR4nO2b2Y9b1R2Av3M3L9djz9iz70z2CUOAhqSClLRBqFCpFQ9ARWkr1Ept1ZYH/gMeeESqeOhLQVVV2oeKCgmB2rSVilKWEEggzWShk8yQWTKZsT1jj3f7+t7Th0kmzI1Jg+oliu4n+cX2ufrp81l/52chpcTjGkqrA7jV8IS48IS48IS48IS48IS48IS4aLkQIcQvhRDHhRBlIcTvWh2P1uoAgEXgBeCbQKDFsbReiJTydQAhxF5gsMXhtH7I3Gp4Qlx4Qlx4Qly0fFIVQmhX4lABVQjhB6pSympLApJStvQFPA9I1+v5VsUjvATRZrw5xIUnxIUnxIUnxMUNl92HlSdu2xn3H85rotb7Xg9x4Qlx4Qlx4Qlx4Qlx4Qlx0fTTrtANhN+HYgaRbSZOOIAV8aOWbZSShVKqQsW61iCZwk6noUlnrqYLUaLtOEPdpLaGSG1XsMdzPLXrA46tjDITj1FNhPAl1I3vDx6JoH5wFmlVwbEbHl/ThKjhMHTHKG6JsbrToNAnESN59g3P8WDoU4JKhU7/ANORGCudIQCkFGRn/MRmunBWUzj5fMPjbJoQZ9sQiwcjlO7L88r+V+hSCvSq4BMaPqFxwH8Wu+MMFjbOleFhI7kv8xxGtp+2UyrOZ7eREKVQwb8iyVVUetU8UQU6VHPjcxUFamymB0aTLO/tQal0Y1YsnFQap1BoWJxNEyLnFunKFcmODrP6NT9+Ubypdq/u+j2z28L8KPwT+oNDRE5oOBfnGhZn05ZdWbGQuTyBuOTl+EHeKY5Qlha2dAAoOBXidp6CU9nULqqqjOkZlM4y+V4VaTb2cq95QqwKdipFbLLI0bfu4qULh1hzKhTluoDLdoWPyjGW7c1CIkqAATXInYOLpCeqVLrMWo+vG03fmOmJHB1TDonLEWYsP2lnPblekipZO0BJ1g5pJhXFvKihrZUbGl/ThdhT04T+/BHhSYMj+Z3MVNeX2KxjsGh1UJDXT2sOkuKn7QwdTqPMXW5ofM2/l5ESpE0w7vCHC/dxaaidWOe/AINx/yWiSgUwmh7WVVp2lolMZTEOR3jz1B7eyNyNjeCRYJk79FDtBgpIXQVRM9FVN1p2c6cmM7Sf9+PoPl4uHeTkXYO0D75Fj+rQqW6eOBUEYjjP8r42+gqdkFxpWFwt6yHV2Xm0f56g74/nGH8xzsl3tvO33G5mqtcPF1UoPL7jJNqjSfJ3RBoaV8t6iNbbgz3QSSkWoBjTcIZL7AnM0quWAX3Td23pcLEQIxkPM1Zs7AGvZULsoW6W97dR7IJyT5VHt5/j634LVdSeQ86nuvDPGuiZLI1MBDTvLBMMokTClHYNkNzjIz/oENySos8sMBRK8VDkLKr44hG8kmyja0aipPM0so80TYgwTeyBTi4d9PHsE28y4Z9nr1FBFyq6UG/Y1kGiXTaIfpKCZKqhcTZtUhVmgFJPgErUZrfvEgNqDl2oKLWOuC4UBM5IkfgDHdDX1dA4m3eWCfrJd2sosTJ7jByDmg9dqDccJp9n78gcq/styn1tDY2zectuIkVsMkvwRJAnp77Lr1M7KDgVLHlzM0LUKOALlXH0xobcNCF2IoE8fpqeYwUWjgzx2vw9FKR1U0JUoRDV84TNEo5+m+1Ujdkk/e/2kMj1cH/65+hGFZ9+rZxMCImqSH4w+iHfD58jqOj4hH6DJ9aXpgupzi+gzS8wuLyD1FIHVb+g6r/2q0sFbAVe//bdfCt0Bl3Yt7eQDZaTdPwbpKasH9quIgRSFXzW28/PlKf4xfDbPGbmuDOwwGq3yYfdnYR6e7BTaWS5/rmR1u1UkytffEgTgtjYfqbNAY7H7uAxc5IxI04+5OPd9nuRHWGUQhG7AUJuvatMRUUYBqvjgu8dfI/vRD4GwJIqJakjHMB2aFT1ZMsLd90IdV2INVTmhe5Jrh70LKlRdnRwaOi15i0nxP7qbpITAcZHPrv2nnR4NXGAI9PbGJipwnISWby5a4wvS/2HjBAITQPlSnbrS2a4siM+0vdYfKVj893L5Eof2oUAgaUidiaDrDam8rtuPURoGkrIpDo+ytzDJkYGOqYs/IsF5Cdn/md7xTQRIZPUTsEP973Po22nWC9/Xz/cJeY7GPq4ihpP08gi+LoKEZEwueEAPQ8sspDoAAK0C5PApIa07evH/tXeIxREyIRohEqvxTPtx4iqKhDAlg5laWGsqIQurCLXMvUKuSb1m0O2jjLzeBRre4GXxg5zfqCXN7r3MDfZx5bV3aj5CkqmgMzmsJMrqF1dyL4Y1bCfSrtBckKjuKvEkxPH6VGNjZTAi6s7OLw0TmQKSKZwiqW6hVyLugmxI37sHevlDQf9aXbqSdqHCvwq/xDZkQi+jIGxaqBpKkouD9EIxcE2ijGNUkxQmSjw04n3+EboLEFlPa9qSZujq2PMTvUyslxFZnPrdSINpG5C9Mtp2t7u49iuHfwmMstW3xKHgjP03rnG4aEJFgrtzK5FWU1HIN6N0ltiYvAiXf4c/b419gTnmDCWiCoKoHOuUuC81cmZo2Ns+WsJYzpOtVRueNFM3YTIbJ726QpWm4+T2UF0YXO/P8GD/iyPBI+zUM3xcbmb08UhjqeHORCd5vHwKSKKSkS5eoG9nk+1pcNMNcoHua2E5gT6J9PYxVJTKohu+H+ZL1PaLXQDpT1CYd8oC09bCMC2FO4dm+NPY3+nik3WqZB1JKuOQZdaoUf1obE5SZSyC6Qdh0OHn2PkDTA/TWDPLdSelP8Pvqi0u349xKpgJxL4473IJRNREZgrgpP6IPGRAvqVFaVdUehSHXThq3mKXbLhvNVN6LyO7y/vN3SJrUXdd6rKf2bZ/tt+AITjsHo5ygHnWYSy/utG2gpsiyZ5JHaaZ8LxjXY5p0TaqfL0qR9jvx2j/2iu3qHdFHUXYmcycDoDiopi6IQjATLnzI09cbrDz4neIJpwuNs3v9FuxTFZsUOszXQw9lEBbWGl6b0D6jiH1H66QG1rQ3RGkcqVIatrSJ+ObRpYbZ8bMlIibIl/MQuLyzj5ItKq1H5uHWj4HFITKdd7TOb63aWgdtFD49eRG3Pr5UNajCfEhSfEhSfEhSfEhSfEhffffxdeD3HhCXHhCXHhCXHhCXHhCXHxXzjQLRKWgtn9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dset = list(zip(train_x, train_y))\n",
    "\n",
    "x, y = dset[0]\n",
    "show_titled_image((x.view(28, 28), str(y.item())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_stacked_threes = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()])\n",
    "valid_stacked_threes = valid_stacked_threes.float() / 255\n",
    "\n",
    "valid_stacked_sevens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()]) \n",
    "valid_stacked_sevens = valid_stacked_sevens.float() / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2038, 784]), torch.Size([2038, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = torch.cat([valid_stacked_threes, valid_stacked_sevens]).view(-1, 28*28)\n",
    "valid_y = tensor([1] * len(valid_stacked_threes) + [0]*len(valid_stacked_sevens)).unsqueeze(1)\n",
    "\n",
    "valid_x.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAGlklEQVR4nO2bS2wcSR2Hv6runvfT47edxAlxII5D4gSiVbILiOeuhLR7WSFxBiGQ9s6NA4gLEkJCiCMSOYDIARE2KFJWC2IPC4k2bCCPjY0x61fiGY/n5fG8urs4+LFR4+SU6Rp5+zvWqKd++uZf1VVd00IpRcBHSN0Beo1AiIdAiIdAiIdAiIdAiIdAiAftQoQQfUKI3wsh6kKID4UQ39SZx9TZ+Q6/ANrAEHAWuCaEuKOUuqcjjNC5UhVCxIESMK2Umt1puwysKKW+ryOT7iFzArB3ZexwBzilKY92IQmg6mmrAEkNWQD9QjaBlKctBdQ0ZAH0C5kFTCHE5BNtZwAtEyponlQBhBC/BRTwLbbvMn8CLuq6y+iuEIDvAVEgD/wG+K4uGdADFdJr9EKF9BSBEA+BEA+BEA/P3Nx9Rb5+YGfcG+4VsV97UCEeAiEeAiEeAiEeAiEeAiEeAiEeAiEeAiEeAiEe9J/LSANhmRiDAzj9aVpDMZpZY+/j+KM2oUIdVvM4pVLX42gXIqMRZDJB6dI4hXOCmYuz/PTwHwBwga/f/jb2rRyHboTg5gEUIsJhZCIOgzlaIylafSbNrKR0UtF3osj59CIhIUgIi7AwiYfblC1QhmTf3dhzxnchRjaDfXiQxxeTuJ8vc2FkkW/0/51DZoUjpsmC7XCrlWPKWuew6X8B+9OjEMhoFJlKUp85zNoFi/bxBq+Mz/PpxBJjZpV3Gsf5We0ID8tDrFWSfGfqHd7I/MeXeE/SfSFCIAwDOZCjdWyAxZcNrr/2EzIS0jJEU9lsuQ4//+ALRP6YJrnc4ehylV/+4HO88eIBEiKs0PZcMTJA7ZNZNkcMasdcjkw9IikUt1r9/KV6kn+Wxlgo9BG+nSAz38A1JY1DKRIx7wmnP3RNiIxHYXSQ/At9uK9u8MWxOX449Dc6OGy58KtHL3LvrRMMvmdz7PptlKtAudhfPU9hJsR033q3oj2T7lVINkNpOkv1OLw6PstkdI0HHXi7Ps211dMs3R1m5K5DbLGKa9t71zVzJvUJm2OxAyakM5whfwFGpx/zo6Gb3G0rrlZnuPyPFxh902RyvoZ6/z6u56Bsc1zy0pn7XErOPuWbu0vXhBiNDuFinKWVHD8ePstf88dZvDtC+t+SxEIFo1DG3ufUUEkISwcLp1vRnkn3hky9SXxFIZwQv7Yvkrpn8amrK6hqDae4gf2U65SAqNEmJA6YEEoVMrNJ4msh4qsmiZUWqlxFtVpd6/J50DUhznoRsV4kBIR227rV2XNE++ZuD2kgDAPXgpTZxBJPG1RdjqGl130QhoGIhHFDirS5ReTjLkQm4shclk7W5aXYLA6C99s2a/k0sVWFUfNn7ukZISIWxcklMbItPhve3ui/15xA5sMkl21kre5Ljp6ZQ5zhLOWTSXKZ7RXqldIF3pyfJvsAYnNFVKniS46eEdLORalOSKaSZQDezR9F3EmS/aCOM+ffrrdnhszmiIU9vcm59BIA/dE6rZyLE/X3N+sZIc2c4NLEAtPRbSG5cB03ZeNE/I3YM0LsKJxJLjFmlgFIWk2seBvX8uNJ6kf0jBA3rJgMPyYj2wDEZJtw2MY1Po5ChEBJMFB7gd5dP0rnX2mi+bavUfTfZXYOqpQEibvXvFZJklgEs9J4orX7aBcizk+xfjZB/FSJ06ESESHZVC0a6zHG5prIYtVXIdqHzNZolI3TLp8ZXmLQiGEJyZbrYFYNrNUKqu7PCnUX7RWyOWpwbmaOL2XuA/B2o4+3KqeILwnU4wKq0fA1j3Yh7ZTgy7kHTIbWAJOHrRFu5o8Q2XBxa/6/R6RdSCeh+Fr8IRkpAZPf/fc89vV+hmZr6PjXsPY5xLXgqJUgJSO4KIrFBNnZNkbBn82cF+0Vskve2WLVCSELISILeVRFz2t3+oTsnPnu1uiWgoKTxGgIKNe0PYzWJsQcHcE+1I+d6wBQVyZ5O4m5JXDLFZTd0ZNLS6+AioZp5cIY0Q6Ocqm5IdbsNEYbVMff5fqTaBPipmPUxk1Sie1T/muVs1x5cI7+VT/Xpf+PvrvMzoYOoKVs1lop7GoIs6n3FR1tQozlAoO3alTms/y5maLhWBipNk7Y3+2+F21C3PoWRqFCJC+5ujHDw40BnJqF0dZbIfrmkM1NVLPFxGWXD298gsGmzVCrCBtlrUee+tYhSqE6bezlFVhe0bJM3w/tS/deIxDiIXj330NQIR4CIR4CIR4CIR4CIR4CIR7+B4exTG9USsnGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_dset = list(zip(valid_x, valid_y))\n",
    "\n",
    "x, y = valid_dset[-1]\n",
    "show_titled_image((x.view(28, 28), str(y.item())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "We will use a 2 layer neural network where the first hidden layer has 16 neurons and\n",
    "the second hidden layer has 8 neurons. Our images are of size $28\\times28$. \n",
    "Therefore we will need a total number of $784\\times16$ weights for our first hidden\n",
    "layer, in addition to $16$ bias parameters. In the second hidden layer, we will need\n",
    "$16\\times8$ weights and $8$ bias parameters. Finally, in the output layer, we will\n",
    "need $8\\times1$ weights and $1$ parameters.\n",
    "\n",
    "### Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=0.1):\n",
    "    return (torch.randn(size) * std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = init_params((28*28, 16))\n",
    "b1 = init_params(16)\n",
    "w2 = init_params((16, 8))\n",
    "b2 = init_params(8)\n",
    "w3 = init_params((8, 1))\n",
    "b3 = init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 16])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 8])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(w1.data.shape)\n",
    "print(b1.data.shape)\n",
    "print(w2.data.shape)\n",
    "print(b2.data.shape)\n",
    "print(w3.data.shape)\n",
    "print(b3.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "We will define some useful activation functions that will be used in the model. We\n",
    "will use `relu` in the hidden layers, and `sigmoid` for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x.max(tensor(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    x = x @ w1 + b1\n",
    "    x = relu(x)\n",
    "    x = x @ w2 + b2\n",
    "    x = relu(x)\n",
    "    x = x @ w3 + b3\n",
    "    x = sigmoid(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "We will need a loss function for gradient descent. In this custom loss function,\n",
    "we are simply calculating the distance from the prediction and the actual target.\n",
    "Since the prediction will be ranged between $0$ and $1$ due the `sigmoid` function\n",
    "in the output layer, we can safely avoid `MSE` loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    return torch.where(targets == 1, 1 - predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 0.495434045791626, Validation Accuracy 0.5068359375\n",
      "Epoch 1: Loss 0.4939988778561962, Validation Accuracy 0.50830078125\n",
      "Epoch 2: Loss 0.4920805437224252, Validation Accuracy 0.5078125\n",
      "Epoch 3: Loss 0.48951365631453847, Validation Accuracy 0.513671875\n",
      "Epoch 4: Loss 0.4860583659337491, Validation Accuracy 0.52197265625\n",
      "Epoch 5: Loss 0.48140528676461203, Validation Accuracy 0.5380859375\n",
      "Epoch 6: Loss 0.4750582308185344, Validation Accuracy 0.55712890625\n",
      "Epoch 7: Loss 0.46626601352983593, Validation Accuracy 0.59521484375\n",
      "Epoch 8: Loss 0.4538784793445042, Validation Accuracy 0.63232421875\n",
      "Epoch 9: Loss 0.43614747207991933, Validation Accuracy 0.68310546875\n",
      "Epoch 10: Loss 0.4110885359803025, Validation Accuracy 0.73388671875\n",
      "Epoch 11: Loss 0.3772355388013684, Validation Accuracy 0.791015625\n",
      "Epoch 12: Loss 0.3348839857748577, Validation Accuracy 0.8408004636686992\n",
      "Epoch 13: Loss 0.2852718453018033, Validation Accuracy 0.8930465574186992\n",
      "Epoch 14: Loss 0.23095537874163413, Validation Accuracy 0.9223037347560976\n",
      "Epoch 15: Loss 0.17962727239545512, Validation Accuracy 0.9324980945121951\n",
      "Epoch 16: Loss 0.139849670383395, Validation Accuracy 0.9451934070121951\n",
      "Epoch 17: Loss 0.11292078368821923, Validation Accuracy 0.9515212144308943\n",
      "Epoch 18: Loss 0.0951358374892449, Validation Accuracy 0.9554274644308943\n",
      "Epoch 19: Loss 0.08304292016795703, Validation Accuracy 0.9568923081808943\n",
      "Epoch 20: Loss 0.07445044336574418, Validation Accuracy 0.9578688706808943\n",
      "Epoch 21: Loss 0.06803456066670466, Validation Accuracy 0.9588255843495935\n",
      "Epoch 22: Loss 0.0630742494320991, Validation Accuracy 0.9607787093495935\n",
      "Epoch 23: Loss 0.05911808019998122, Validation Accuracy 0.9612669905995935\n",
      "Epoch 24: Loss 0.0558835715815729, Validation Accuracy 0.9622435530995935\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "\n",
    "    for xb, yb, in dl:\n",
    "        preds = forward(xb)\n",
    "        loss = mnist_loss(preds, yb)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        w1.data -= w1.grad * lr\n",
    "        w2.data -= w2.grad * lr\n",
    "        w3.data -= w3.grad * lr\n",
    "\n",
    "        b1.data -= b1.grad * lr\n",
    "        b2.data -= b2.grad * lr\n",
    "        b3.data -= b3.grad * lr\n",
    "\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n",
    "        w3.grad.zero_()\n",
    "        b1.grad.zero_()\n",
    "        b2.grad.zero_()\n",
    "        b3.grad.zero_()\n",
    "    \n",
    "    acc = []\n",
    "    for vx, vy in valid_dl:\n",
    "        v_preds = forward(vx)\n",
    "        v_preds = torch.where(v_preds >= 0.5, 1, 0)\n",
    "        acc.append(torch.sum(v_preds == vy).item() / vx.shape[0])\n",
    "\n",
    "    print(\"Epoch {}: Loss {}, Validation Accuracy {}\".format(epoch, sum(losses) / len(losses), \n",
    "            sum(acc) / len(acc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
